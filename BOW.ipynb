{"cells":[{"cell_type":"code","execution_count":5,"metadata":{"id":"QOvn66pmjoPJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1643996172307,"user_tz":-60,"elapsed":16000,"user":{"displayName":"ayberk tecimer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDaP-YEMaVtdZNLQ7v0pH6E9_gs4QaOtrqxEDk5w=s64","userId":"07258608254476078813"}},"outputId":"e814f10e-2715-4359-9337-e6b88d1547d8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.0)\n","Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.10.0.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.13.3)\n","Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0.dev2021122109)\n","Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.43.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.5)\n","Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.23.1)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n","Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n","Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (13.0.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.0)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.10.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.7.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.1.1)\n"]}],"source":["import os\n","# to use or not to use GPU\n","#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\" \n","!sudo pip install tensorflow --upgrade\n","# packages for model graph visualization\n","#!pip install -q pydot\n","# install graphviz https://graphviz.gitlab.io/download/ \n","\n","import tensorflow as tf\n","from tensorflow.keras import layers\n","import tensorflow_hub as hub\n","!pip install -q -U tensorflow-text\n","import tensorflow_text as text\n","!pip install -q tf-models-official\n","\n","import json\n","import re\n","import random\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","#save_path = \"/content/drive/My Drive/Colab Notebooks/\""]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-eD1puUmjrzq","executionInfo":{"status":"ok","timestamp":1643996202609,"user_tz":-60,"elapsed":25599,"user":{"displayName":"ayberk tecimer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDaP-YEMaVtdZNLQ7v0pH6E9_gs4QaOtrqxEDk5w=s64","userId":"07258608254476078813"}},"outputId":"8c15fc70-b67b-4b4a-bb80-8136126e7fd3"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["save_path = \"/content/drive/My Drive/Colab Notebooks/\""],"metadata":{"id":"h9RE7SSamfg_","executionInfo":{"status":"ok","timestamp":1643996203195,"user_tz":-60,"elapsed":591,"user":{"displayName":"ayberk tecimer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDaP-YEMaVtdZNLQ7v0pH6E9_gs4QaOtrqxEDk5w=s64","userId":"07258608254476078813"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["%tensorflow_version 2.x\n","import tensorflow as tf\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"virpP5iPmkZs","executionInfo":{"status":"ok","timestamp":1643996203646,"user_tz":-60,"elapsed":12,"user":{"displayName":"ayberk tecimer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDaP-YEMaVtdZNLQ7v0pH6E9_gs4QaOtrqxEDk5w=s64","userId":"07258608254476078813"}},"outputId":"e4b1039e-5be3-4e5c-ef78-a7da515ed9b5"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Found GPU at: /device:GPU:0\n"]}]},{"cell_type":"code","source":["# checking if we have access to a GPU\n","\n","tf.config.list_physical_devices()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2j4PiF_6mtQm","executionInfo":{"status":"ok","timestamp":1643996203647,"user_tz":-60,"elapsed":11,"user":{"displayName":"ayberk tecimer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDaP-YEMaVtdZNLQ7v0pH6E9_gs4QaOtrqxEDk5w=s64","userId":"07258608254476078813"}},"outputId":"832561bd-63dc-4c9a-fd4b-bc53500a653d"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n"," PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["#@title Data Loading & Preprocessing\n"],"metadata":{"id":"S3sMA5T_mtkz","executionInfo":{"status":"ok","timestamp":1643996203648,"user_tz":-60,"elapsed":9,"user":{"displayName":"ayberk tecimer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDaP-YEMaVtdZNLQ7v0pH6E9_gs4QaOtrqxEDk5w=s64","userId":"07258608254476078813"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","execution_count":57,"metadata":{"id":"gj9DCuWKsl1l","executionInfo":{"status":"ok","timestamp":1643996866335,"user_tz":-60,"elapsed":3360,"user":{"displayName":"ayberk tecimer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDaP-YEMaVtdZNLQ7v0pH6E9_gs4QaOtrqxEDk5w=s64","userId":"07258608254476078813"}}},"outputs":[],"source":["with open(save_path+'kafka_data_preprocessed_high_occurrence_50.json') as f:\n","    data = json.load(f)\n","    # shuffle data\n","    random.shuffle(data)\n","    # create description and assignee list\n","    desc_data = []\n","    assignee_data = []\n","    for item in data:\n","        desc_data.append(item['description'])\n","        assignee_data.append(item['assignee'])"]},{"cell_type":"code","execution_count":58,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0bpi1aHWsl1m","executionInfo":{"status":"ok","timestamp":1643996866336,"user_tz":-60,"elapsed":23,"user":{"displayName":"ayberk tecimer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDaP-YEMaVtdZNLQ7v0pH6E9_gs4QaOtrqxEDk5w=s64","userId":"07258608254476078813"}},"outputId":"97f1034f-65c6-4bea-dc8b-501d54782a22"},"outputs":[{"output_type":"stream","name":"stdout","text":["sample assignees: ['Jay Kreps', 'Jiangjie Qin']\n","sample descriptions: ['Currently it is a bit of a mess:jkreps-mn:kafka-git jkreps$ ls binkafka-console-consumer-log4j.properties kafka-producer-perf-test.sh kafka-server-stop.sh zookeeper-server-stop.shkafka-console-consumer.sh kafka-producer-shell.sh kafka-simple-consumer-perf-test.sh zookeeper-shell.shkafka-console-producer.sh kafka-replay-log-producer.sh kafka-simple-consumer-shell.shkafka-consumer-perf-test.sh kafka-run-class.sh run-rat.shkafka-consumer-shell.sh kafka-server-start.sh zookeeper-server-start.shI think all the *-shell.sh scripts and all the *-simple-perf-test.sh scripts should die. If anyone has a use for these test classes we can keep them around and use the via kafka-run-class, but they are clearly not made for normal people to use. The *-shell.sh scripts are obsolete now that we have the *-console-*.sh scripts, since these do everything the old scripts did and more. I recommend we also delete the code for these.I would like to change each tool so that it produces a usage line explaining what it does when run without arguments. Currently I actually had to go read the code to figure out what some of these are.I would like to clean up places where the arguments are non-standard. Argument names should be the same across all the tools.I would also like to rename kafka-replay-log-producer.sh to kafka-copy-topic.sh. I think this tool should also accept two zookeeper urls, the url of the input cluster and the url of the output cluster so this tool can be used to copy between clusters. I think we can have a --zookeeper a --input-zookeeper and a --output-zookeeper where --zookeeper is equivalent to setting both the input and the output zookeeper. Also confused why the options for this list --brokerinfo which can be either a zk url or brokerlist AND also --zookeeper which must be a zk url.Any objections to all this? Any other gripes people have while I am in there?', \"The decision about this JIRA assignment is still under discussion with [~becket_qin]. Not going to implement without his agreement.This JIRA includes:When the broker receives a message, it checks the configs:1. If message.timestamp.type=LogAppendTime, the server over-writes the timestamp with its current local timeMessage could be compressed or not compressed. In either case, the timestamp is always over-written to broker's current time2. If message.timestamp.type=CreateTime, the server calculated the difference between the current time on broker and Timestamp in the message:If difference is within max.message.time.difference.ms, the server will accept it and append it to the log. For compressed message, server will update the timestamp in compressed message to -1: this means that CreateTime is used and the timestamp is in each individual inner message.If difference is higher than max.message.time.difference.ms, the server will reject the entire batch with TimestampExceededThresholdException.(Actually adding the timestamp to the message and adding configs are covered by KAFKA-3025).\"]\n"]}],"source":["print('sample assignees:', assignee_data[0:2])\n","print('sample descriptions:', desc_data[0:2])"]},{"cell_type":"code","execution_count":59,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FhnwNBlosl1n","executionInfo":{"status":"ok","timestamp":1643996866337,"user_tz":-60,"elapsed":22,"user":{"displayName":"ayberk tecimer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDaP-YEMaVtdZNLQ7v0pH6E9_gs4QaOtrqxEDk5w=s64","userId":"07258608254476078813"}},"outputId":"1ce73a43-4f21-4199-85c0-ba032c325406"},"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(b'Currently it is a bit of a mess:jkreps-mn:kafka-git jkreps$ ls binkafka-console-consumer-log4j.properties kafka-producer-perf-test.sh kafka-server-stop.sh zookeeper-server-stop.shkafka-console-consumer.sh kafka-producer-shell.sh kafka-simple-consumer-perf-test.sh zookeeper-shell.shkafka-console-producer.sh kafka-replay-log-producer.sh kafka-simple-consumer-shell.shkafka-consumer-perf-test.sh kafka-run-class.sh run-rat.shkafka-consumer-shell.sh kafka-server-start.sh zookeeper-server-start.shI think all the *-shell.sh scripts and all the *-simple-perf-test.sh scripts should die. If anyone has a use for these test classes we can keep them around and use the via kafka-run-class, but they are clearly not made for normal people to use. The *-shell.sh scripts are obsolete now that we have the *-console-*.sh scripts, since these do everything the old scripts did and more. I recommend we also delete the code for these.I would like to change each tool so that it produces a usage line explaining what it does when run without arguments. Currently I actually had to go read the code to figure out what some of these are.I would like to clean up places where the arguments are non-standard. Argument names should be the same across all the tools.I would also like to rename kafka-replay-log-producer.sh to kafka-copy-topic.sh. I think this tool should also accept two zookeeper urls, the url of the input cluster and the url of the output cluster so this tool can be used to copy between clusters. I think we can have a --zookeeper a --input-zookeeper and a --output-zookeeper where --zookeeper is equivalent to setting both the input and the output zookeeper. Also confused why the options for this list --brokerinfo which can be either a zk url or brokerlist AND also --zookeeper which must be a zk url.Any objections to all this? Any other gripes people have while I am in there?', shape=(), dtype=string)\n","tf.Tensor(b\"The decision about this JIRA assignment is still under discussion with [~becket_qin]. Not going to implement without his agreement.This JIRA includes:When the broker receives a message, it checks the configs:1. If message.timestamp.type=LogAppendTime, the server over-writes the timestamp with its current local timeMessage could be compressed or not compressed. In either case, the timestamp is always over-written to broker's current time2. If message.timestamp.type=CreateTime, the server calculated the difference between the current time on broker and Timestamp in the message:If difference is within max.message.time.difference.ms, the server will accept it and append it to the log. For compressed message, server will update the timestamp in compressed message to -1: this means that CreateTime is used and the timestamp is in each individual inner message.If difference is higher than max.message.time.difference.ms, the server will reject the entire batch with TimestampExceededThresholdException.(Actually adding the timestamp to the message and adding configs are covered by KAFKA-3025).\", shape=(), dtype=string)\n"]}],"source":["# transform description data to tensorflow dataset\n","descriptions = tf.data.Dataset.from_tensor_slices(desc_data)\n","for input in descriptions.take(2):\n","    print(input)"]},{"cell_type":"code","execution_count":60,"metadata":{"id":"5Ftwycc5sl1o","executionInfo":{"status":"ok","timestamp":1643996866640,"user_tz":-60,"elapsed":22,"user":{"displayName":"ayberk tecimer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDaP-YEMaVtdZNLQ7v0pH6E9_gs4QaOtrqxEDk5w=s64","userId":"07258608254476078813"}}},"outputs":[],"source":["# target vectorize assignee data\n","assignee_dict = {assignee: i for i, assignee in enumerate(list(set(assignee_data)))}"]},{"cell_type":"code","execution_count":61,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GMpeS3_rsl1p","executionInfo":{"status":"ok","timestamp":1643996866641,"user_tz":-60,"elapsed":23,"user":{"displayName":"ayberk tecimer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDaP-YEMaVtdZNLQ7v0pH6E9_gs4QaOtrqxEDk5w=s64","userId":"07258608254476078813"}},"outputId":"eca5b9ed-cc46-456e-fae0-2a9bafb617f5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0, 2, 28, 21, 21, 23, 8, 21, 30, 31]"]},"metadata":{},"execution_count":61}],"source":["# create target vector\n","assignee_vector = [assignee_dict[assignee] for assignee in assignee_data]\n","assignee_vector[:10]"]},{"cell_type":"code","execution_count":62,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"58XXBC2csl1q","executionInfo":{"status":"ok","timestamp":1643996866642,"user_tz":-60,"elapsed":22,"user":{"displayName":"ayberk tecimer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDaP-YEMaVtdZNLQ7v0pH6E9_gs4QaOtrqxEDk5w=s64","userId":"07258608254476078813"}},"outputId":"d76f3efb-f660-471a-8c55-cc2c2d69c1be"},"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(0, shape=(), dtype=int32)\n","tf.Tensor(2, shape=(), dtype=int32)\n"]}],"source":["# assignee target vector to one hot vector\n","assignee_tensor = tf.data.Dataset.from_tensor_slices(assignee_vector)\n","\n","for assignee in assignee_tensor.take(2):\n","    print(assignee)"]},{"cell_type":"code","source":["#@title BOW\n"],"metadata":{"id":"nqcBsfLc6WWt","executionInfo":{"status":"ok","timestamp":1643996866642,"user_tz":-60,"elapsed":19,"user":{"displayName":"ayberk tecimer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDaP-YEMaVtdZNLQ7v0pH6E9_gs4QaOtrqxEDk5w=s64","userId":"07258608254476078813"}}},"execution_count":63,"outputs":[]},{"cell_type":"code","source":["input_vectorizer = layers.TextVectorization(\n","    split = \"whitespace\",\n","    output_mode='multi_hot')"],"metadata":{"id":"gSwCoAy56fFA","executionInfo":{"status":"ok","timestamp":1643996866642,"user_tz":-60,"elapsed":19,"user":{"displayName":"ayberk tecimer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDaP-YEMaVtdZNLQ7v0pH6E9_gs4QaOtrqxEDk5w=s64","userId":"07258608254476078813"}}},"execution_count":64,"outputs":[]},{"cell_type":"code","source":["input_vectorizer.adapt(descriptions)"],"metadata":{"id":"C88yr5ZC7y55","executionInfo":{"status":"ok","timestamp":1643996876494,"user_tz":-60,"elapsed":9870,"user":{"displayName":"ayberk tecimer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDaP-YEMaVtdZNLQ7v0pH6E9_gs4QaOtrqxEDk5w=s64","userId":"07258608254476078813"}}},"execution_count":65,"outputs":[]},{"cell_type":"code","source":["output_vectorizer = layers.CategoryEncoding(num_tokens = len(assignee_dict), output_mode=\"one_hot\")"],"metadata":{"id":"BVCw53TlN7cp","executionInfo":{"status":"ok","timestamp":1643996876495,"user_tz":-60,"elapsed":18,"user":{"displayName":"ayberk tecimer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDaP-YEMaVtdZNLQ7v0pH6E9_gs4QaOtrqxEDk5w=s64","userId":"07258608254476078813"}}},"execution_count":66,"outputs":[]},{"cell_type":"code","source":["for description in descriptions.take(2):\n","    print(description)\n","    print(input_vectorizer(description))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ssQh6oSGayeJ","executionInfo":{"status":"ok","timestamp":1643996876496,"user_tz":-60,"elapsed":18,"user":{"displayName":"ayberk tecimer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDaP-YEMaVtdZNLQ7v0pH6E9_gs4QaOtrqxEDk5w=s64","userId":"07258608254476078813"}},"outputId":"c287ef81-1f7e-4453-d976-95173ac2072d"},"execution_count":67,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(b'Currently it is a bit of a mess:jkreps-mn:kafka-git jkreps$ ls binkafka-console-consumer-log4j.properties kafka-producer-perf-test.sh kafka-server-stop.sh zookeeper-server-stop.shkafka-console-consumer.sh kafka-producer-shell.sh kafka-simple-consumer-perf-test.sh zookeeper-shell.shkafka-console-producer.sh kafka-replay-log-producer.sh kafka-simple-consumer-shell.shkafka-consumer-perf-test.sh kafka-run-class.sh run-rat.shkafka-consumer-shell.sh kafka-server-start.sh zookeeper-server-start.shI think all the *-shell.sh scripts and all the *-simple-perf-test.sh scripts should die. If anyone has a use for these test classes we can keep them around and use the via kafka-run-class, but they are clearly not made for normal people to use. The *-shell.sh scripts are obsolete now that we have the *-console-*.sh scripts, since these do everything the old scripts did and more. I recommend we also delete the code for these.I would like to change each tool so that it produces a usage line explaining what it does when run without arguments. Currently I actually had to go read the code to figure out what some of these are.I would like to clean up places where the arguments are non-standard. Argument names should be the same across all the tools.I would also like to rename kafka-replay-log-producer.sh to kafka-copy-topic.sh. I think this tool should also accept two zookeeper urls, the url of the input cluster and the url of the output cluster so this tool can be used to copy between clusters. I think we can have a --zookeeper a --input-zookeeper and a --output-zookeeper where --zookeeper is equivalent to setting both the input and the output zookeeper. Also confused why the options for this list --brokerinfo which can be either a zk url or brokerlist AND also --zookeeper which must be a zk url.Any objections to all this? Any other gripes people have while I am in there?', shape=(), dtype=string)\n","tf.Tensor([0. 1. 0. ... 0. 0. 0.], shape=(42790,), dtype=float32)\n","tf.Tensor(b\"The decision about this JIRA assignment is still under discussion with [~becket_qin]. Not going to implement without his agreement.This JIRA includes:When the broker receives a message, it checks the configs:1. If message.timestamp.type=LogAppendTime, the server over-writes the timestamp with its current local timeMessage could be compressed or not compressed. In either case, the timestamp is always over-written to broker's current time2. If message.timestamp.type=CreateTime, the server calculated the difference between the current time on broker and Timestamp in the message:If difference is within max.message.time.difference.ms, the server will accept it and append it to the log. For compressed message, server will update the timestamp in compressed message to -1: this means that CreateTime is used and the timestamp is in each individual inner message.If difference is higher than max.message.time.difference.ms, the server will reject the entire batch with TimestampExceededThresholdException.(Actually adding the timestamp to the message and adding configs are covered by KAFKA-3025).\", shape=(), dtype=string)\n","tf.Tensor([0. 1. 0. ... 0. 0. 0.], shape=(42790,), dtype=float32)\n"]}]},{"cell_type":"code","source":["for bow_assignee in assignee_tensor.take(2):\n","    print(bow_assignee)\n","    print(output_vectorizer(bow_assignee))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LsjaN-ZuOxhf","executionInfo":{"status":"ok","timestamp":1643996876496,"user_tz":-60,"elapsed":15,"user":{"displayName":"ayberk tecimer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDaP-YEMaVtdZNLQ7v0pH6E9_gs4QaOtrqxEDk5w=s64","userId":"07258608254476078813"}},"outputId":"ac32ad67-7265-46f0-dc9f-1e4c0a926382"},"execution_count":68,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(0, shape=(), dtype=int32)\n","tf.Tensor(\n","[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(36,), dtype=float32)\n","tf.Tensor(2, shape=(), dtype=int32)\n","tf.Tensor(\n","[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(36,), dtype=float32)\n"]}]},{"cell_type":"code","source":["bow_dataset = tf.data.Dataset.zip((descriptions, assignee_tensor))\n","\n","def vectorize_dataset(description, assignee):\n","\n","  return input_vectorizer(description), output_vectorizer(assignee)\n","\n","bow_dataset = bow_dataset.map(vectorize_dataset)\n","\n","for description, assignee in bow_dataset.take(2):\n","    print(description, assignee)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7YAACkLCO4V7","executionInfo":{"status":"ok","timestamp":1643996877015,"user_tz":-60,"elapsed":530,"user":{"displayName":"ayberk tecimer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDaP-YEMaVtdZNLQ7v0pH6E9_gs4QaOtrqxEDk5w=s64","userId":"07258608254476078813"}},"outputId":"eac7445b-aa3d-4fb5-a036-7ca64a1ab3ed"},"execution_count":69,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor([0. 1. 0. ... 0. 0. 0.], shape=(42790,), dtype=float32) tf.Tensor(\n","[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(36,), dtype=float32)\n","tf.Tensor([0. 1. 0. ... 0. 0. 0.], shape=(42790,), dtype=float32) tf.Tensor(\n","[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(36,), dtype=float32)\n"]}]},{"cell_type":"code","source":["bow_dataset = bow_dataset.shuffle(len(list(bow_dataset)), seed = 42)"],"metadata":{"id":"1PCJuUS2QDUs","executionInfo":{"status":"ok","timestamp":1643996881343,"user_tz":-60,"elapsed":4331,"user":{"displayName":"ayberk tecimer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDaP-YEMaVtdZNLQ7v0pH6E9_gs4QaOtrqxEDk5w=s64","userId":"07258608254476078813"}}},"execution_count":70,"outputs":[]},{"cell_type":"code","source":["# batching the dataset\n","BATCH_SIZE = 32\n","VAL_SIZE = 0.15\n","bow_dataset = bow_dataset.batch(batch_size=BATCH_SIZE)\n","\n","for line, label in bow_dataset.take(2):\n","    print(line.shape)\n","    \n","print(len(list(bow_dataset)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6OM-BxaEQTzA","executionInfo":{"status":"ok","timestamp":1643996887297,"user_tz":-60,"elapsed":5978,"user":{"displayName":"ayberk tecimer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDaP-YEMaVtdZNLQ7v0pH6E9_gs4QaOtrqxEDk5w=s64","userId":"07258608254476078813"}},"outputId":"455dd237-b194-46a6-c689-188fad925a79"},"execution_count":71,"outputs":[{"output_type":"stream","name":"stdout","text":["(32, 42790)\n","(32, 42790)\n","136\n"]}]},{"cell_type":"code","source":["# splitting the dataset into validation and test data\n","val_size = round(VAL_SIZE*(len(list(bow_dataset))))\n","\n","val_dataset = bow_dataset.take(val_size) \n","train_dataset = bow_dataset.skip(val_size)"],"metadata":{"id":"9QlZC2xlQv4y","executionInfo":{"status":"ok","timestamp":1643996889914,"user_tz":-60,"elapsed":2629,"user":{"displayName":"ayberk tecimer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDaP-YEMaVtdZNLQ7v0pH6E9_gs4QaOtrqxEDk5w=s64","userId":"07258608254476078813"}}},"execution_count":72,"outputs":[]},{"cell_type":"code","source":["len(list(train_dataset))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-FayuUtdSyJ2","executionInfo":{"status":"ok","timestamp":1643996892878,"user_tz":-60,"elapsed":2966,"user":{"displayName":"ayberk tecimer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDaP-YEMaVtdZNLQ7v0pH6E9_gs4QaOtrqxEDk5w=s64","userId":"07258608254476078813"}},"outputId":"84dc1701-185d-4041-b85d-b56da566d5b0"},"execution_count":73,"outputs":[{"output_type":"execute_result","data":{"text/plain":["116"]},"metadata":{},"execution_count":73}]},{"cell_type":"code","source":["vocab_size = input_vectorizer.vocabulary_size()\n","bow_model = tf.keras.Sequential([\n","  tf.keras.layers.Dense(1024, input_shape=(vocab_size,), activation='relu'),\n","  tf.keras.layers.Dense(256, activation='relu'),\n","  tf.keras.layers.Dense(64, activation='relu'),\n","  tf.keras.layers.Dense(len(assignee_dict), activation = \"softmax\")\n","])"],"metadata":{"id":"I5jaPN_lASXa","executionInfo":{"status":"ok","timestamp":1643996893196,"user_tz":-60,"elapsed":5,"user":{"displayName":"ayberk tecimer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDaP-YEMaVtdZNLQ7v0pH6E9_gs4QaOtrqxEDk5w=s64","userId":"07258608254476078813"}}},"execution_count":74,"outputs":[]},{"cell_type":"code","source":["tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs\")"],"metadata":{"id":"enOaqLBNB4_v","executionInfo":{"status":"ok","timestamp":1643996893197,"user_tz":-60,"elapsed":6,"user":{"displayName":"ayberk tecimer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDaP-YEMaVtdZNLQ7v0pH6E9_gs4QaOtrqxEDk5w=s64","userId":"07258608254476078813"}}},"execution_count":75,"outputs":[]},{"cell_type":"code","source":["bow_model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n","              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n","              metrics=['accuracy'])"],"metadata":{"id":"FlD8LVfECAMH","executionInfo":{"status":"ok","timestamp":1643996893197,"user_tz":-60,"elapsed":6,"user":{"displayName":"ayberk tecimer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDaP-YEMaVtdZNLQ7v0pH6E9_gs4QaOtrqxEDk5w=s64","userId":"07258608254476078813"}}},"execution_count":76,"outputs":[]},{"cell_type":"code","source":["bow_model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iGPVkjHHEhVs","executionInfo":{"status":"ok","timestamp":1643996893198,"user_tz":-60,"elapsed":6,"user":{"displayName":"ayberk tecimer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDaP-YEMaVtdZNLQ7v0pH6E9_gs4QaOtrqxEDk5w=s64","userId":"07258608254476078813"}},"outputId":"18c94244-7c34-46bf-eaa4-89e4568aefe2"},"execution_count":77,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_6 (Dense)             (None, 1024)              43817984  \n","                                                                 \n"," dense_7 (Dense)             (None, 256)               262400    \n","                                                                 \n"," dense_8 (Dense)             (None, 64)                16448     \n","                                                                 \n"," dense_9 (Dense)             (None, 36)                2340      \n","                                                                 \n","=================================================================\n","Total params: 44,099,172\n","Trainable params: 44,099,172\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["for inputs,targets in train_dataset.take(1):\n","    print(inputs)\n","    outputs = bow_model(inputs)\n","\n","    print(outputs.shape)\n","    print(outputs)\n","    print(targets)"],"metadata":{"id":"sbdbI2nISA37","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1643996903039,"user_tz":-60,"elapsed":5509,"user":{"displayName":"ayberk tecimer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDaP-YEMaVtdZNLQ7v0pH6E9_gs4QaOtrqxEDk5w=s64","userId":"07258608254476078813"}},"outputId":"6e270922-ad92-48ea-ea0c-c3411d008e4e"},"execution_count":78,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(\n","[[0. 1. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 1. ... 0. 0. 0.]\n"," ...\n"," [0. 1. 0. ... 0. 0. 0.]\n"," [0. 1. 1. ... 0. 0. 0.]\n"," [0. 1. 0. ... 0. 0. 0.]], shape=(32, 42790), dtype=float32)\n","(32, 36)\n","tf.Tensor(\n","[[0.02692838 0.02727757 0.02934074 ... 0.02670073 0.03042019 0.02790688]\n"," [0.02760849 0.02778633 0.02817575 ... 0.02769669 0.02764769 0.02770082]\n"," [0.0279574  0.02816743 0.02760368 ... 0.02774283 0.02775576 0.02766822]\n"," ...\n"," [0.02736332 0.02817666 0.02850916 ... 0.02725299 0.02842584 0.02827456]\n"," [0.02730815 0.02779472 0.02886209 ... 0.02752302 0.02877241 0.0276683 ]\n"," [0.02800682 0.02746277 0.02797613 ... 0.02696937 0.02936696 0.02778163]], shape=(32, 36), dtype=float32)\n","tf.Tensor(\n","[[0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," ...\n"," [0. 1. 0. ... 0. 0. 0.]\n"," [0. 0. 1. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]], shape=(32, 36), dtype=float32)\n"]}]},{"cell_type":"code","source":["bow_model.fit(\n","    train_dataset,\n","    validation_data=val_dataset,\n","    epochs=15,\n","    callbacks=[tensorboard_callback])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ToexcSZaCaRf","outputId":"248bd802-4b31-4944-db08-7d0b1e59cb80"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/15\n","WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f5254075050> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f5254075050> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n","  api_dispatcher = getattr(op_dispatch_handler, TYPE_BASED_DISPATCH_ATTR,\n"]},{"output_type":"stream","name":"stdout","text":["116/116 [==============================] - ETA: 0s - loss: 3.2592 - accuracy: 0.1512WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f5253fb4320> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f5253fb4320> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","116/116 [==============================] - 9s 51ms/step - loss: 3.2592 - accuracy: 0.1512 - val_loss: 2.3409 - val_accuracy: 0.4187\n","Epoch 2/15\n","116/116 [==============================] - 8s 51ms/step - loss: 1.8393 - accuracy: 0.5165 - val_loss: 0.5856 - val_accuracy: 0.8969\n","Epoch 3/15\n"," 21/116 [====>.........................] - ETA: 2s - loss: 0.6257 - accuracy: 0.8705"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"MoM1Pi0Pb6Ig"},"execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python"},"orig_nbformat":4,"colab":{"name":"BOW.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}