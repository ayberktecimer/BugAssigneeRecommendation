{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Installing packages that are not in the colab"
      ],
      "metadata": {
        "id": "Jifo64Poxkr3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo pip install tensorflow --upgrade\n",
        "!pip install -q -U tensorflow-text\n",
        "!pip install -q tf-models-official\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UC_WYYs25_I0",
        "outputId": "cd59ebe1-3e4c-4698-833a-67b92d51a0a6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 5.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (13.0.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.44.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.13.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.24.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.5)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.10.0.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
            "Installing collected packages: tf-estimator-nightly\n",
            "Successfully installed tf-estimator-nightly-2.8.0.dev2021122109\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 5.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 5.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 47.8 MB 1.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 234 kB 46.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 38.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 42.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 636 kB 10.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 90 kB 5.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 352 kB 33.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 99 kB 4.2 MB/s \n",
            "\u001b[?25h  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Necessary Packages\n",
        "\n"
      ],
      "metadata": {
        "id": "0QTPYlQxw9Tt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from official.nlp import optimization  # to create AdamW optimizer\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "from keras import regularizers\n",
        "import json\n",
        "import re\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n"
      ],
      "metadata": {
        "id": "z2RqS0g258-U"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mounting Colab to drive so that we can load/save data"
      ],
      "metadata": {
        "id": "BBtOL12uxK0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91pvwgkH6MrR",
        "outputId": "e60e2648-0d4e-426e-8ee1-29b69bf49aa7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = \"/content/drive/My Drive/datasets/\""
      ],
      "metadata": {
        "id": "0Mql8xnzpd3P"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_save_path = \"/content/drive/My Drive/demo-models/\""
      ],
      "metadata": {
        "id": "lBp5se7e2gpi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = \"/content/drive/My Drive/Colab Notebooks/\""
      ],
      "metadata": {
        "id": "rL-Zfcq36Q6V"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking if we have an access to gpu"
      ],
      "metadata": {
        "id": "czjNO1aNxSha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 2.x\n",
        "'''device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "bwqhqXhY6VPu",
        "outputId": "72f88b34-73f7-43a9-a9a0-5688a928452f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"device_name = tf.test.gpu_device_name()\\nif device_name != '/device:GPU:0':\\n  raise SystemError('GPU device not found')\\nprint('Found GPU at: {}'.format(device_name))\""
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tf.config.list_physical_devices()"
      ],
      "metadata": {
        "id": "r_Tx9q9X6XwN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "196d2a1b-b2dd-428b-cc4d-adfcace3affa"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project Idea & Insights (Bug Assignee Recommendation)"
      ],
      "metadata": {
        "id": "agvcRDw4Msru"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Software Analytics aims to make software developers life easier with building software tools, developing heuristic/ml/dl models using software artifacts (e.g. source code, software repositories, feature specifications, issue/bug reports, test cases, execution traces/logs, and real-world user feedback). To have a better understanding, you may refer to the link (https://www.microsoft.com/en-us/research/group/software-analytics/), it is a short but well-defined description of Software Analytics. The idea behind the project is on bug report assignee recommendation. One of the most famous bug report tools is JIRA, and there are many open source project data available (e.g. https://issues.apache.org/jira/projects/). I chose Apache Kafka as the dataset, it is an open-source distributed event streaming platform, commonly used by Data Engineers. A bug report consists of several fields (Description, Assignee, Reporter, Status, Priority, Resolution, Affects Version/s, Fix Version/s, Component/s) and many more. A bug description is a text field that information related with the bug is defined and an assignee is a developer who is usually assigned by a Team Lead and responsible for fixing that bug. The main idea behind the project is to predict an assignee to a bug report by using its' bug description. This project can be helpful for Software Team Leads while assigning bugs to Software Developers in a team."
      ],
      "metadata": {
        "id": "JnsMKYF_Mz5y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading & Preprocessing"
      ],
      "metadata": {
        "id": "gnGWgiBxxanp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reading Bug Assignee data with bug descriptions and assignees"
      ],
      "metadata": {
        "id": "FNNbxrwVxrZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(data_path+'project_data.json') as f:\n",
        "    data = json.load(f)\n",
        "    # create description and assignee list\n",
        "    desc_data = []\n",
        "    assignee_data = []\n",
        "    for item in data:\n",
        "        desc_data.append(item['description'])\n",
        "        assignee_data.append(item['assignee'])"
      ],
      "metadata": {
        "id": "gWq0-E9I6cKd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Transform description data to tensorflow dataset"
      ],
      "metadata": {
        "id": "yDAda-L1xwN5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "descriptions = tf.data.Dataset.from_tensor_slices(desc_data)"
      ],
      "metadata": {
        "id": "f0BF3kqi6efP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   I have mapped original names to fake names, so that I don't process any personal data.\n",
        "*   Cell below creates assignee dictionary with id's so that we can feed into neural networks & also can revert predictions (id's) to assignee by names."
      ],
      "metadata": {
        "id": "c19p5-XFx0R1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assignee_dict = {assignee: i for i, assignee in enumerate(list(set(assignee_data)))}\n",
        "assignee_dict"
      ],
      "metadata": {
        "id": "Gi9NT0Qd6j3E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fc4ec86-2430-4cf8-853f-ad902ee8a0b6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Alex': 0,\n",
              " 'Alice': 6,\n",
              " 'Anna': 8,\n",
              " 'Barbara': 3,\n",
              " 'Bob': 34,\n",
              " 'Brandon': 28,\n",
              " 'Charlie': 11,\n",
              " 'David': 35,\n",
              " 'Debra': 7,\n",
              " 'Eric': 30,\n",
              " 'George': 12,\n",
              " 'Henry': 22,\n",
              " 'Isabella': 23,\n",
              " 'Jan': 29,\n",
              " 'Jennifer': 31,\n",
              " 'Joe': 33,\n",
              " 'Johannes': 20,\n",
              " 'Julia': 18,\n",
              " 'Lawrence': 9,\n",
              " 'Linda': 17,\n",
              " 'Lisa': 15,\n",
              " 'Maria': 32,\n",
              " 'Mary': 16,\n",
              " 'Matthew': 1,\n",
              " 'Melissa': 10,\n",
              " 'Natalie': 19,\n",
              " 'Patricia': 21,\n",
              " 'Peter': 26,\n",
              " 'Richard': 2,\n",
              " 'Russell': 13,\n",
              " 'Sara': 5,\n",
              " 'Sophia': 24,\n",
              " 'Steven': 4,\n",
              " 'Thomas': 27,\n",
              " 'Tom': 25,\n",
              " 'Vanessa': 14}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving assignee dictionary to a json file so that in the demo notebook we can remap predictions (id's) to fake names "
      ],
      "metadata": {
        "id": "YDDGk5nEycJX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''with open(data_path + 'assignee_dict.json', 'w') as fp:\n",
        "    json.dump(assignee_dict, fp)'''"
      ],
      "metadata": {
        "id": "nuxA1OUGAZs5"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a target vector with id's"
      ],
      "metadata": {
        "id": "7RO6vxNSynuA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assignee_vector = [assignee_dict[assignee] for assignee in assignee_data]\n",
        "assignee_vector[:10]"
      ],
      "metadata": {
        "id": "jP_Jx81R6nOZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15f11f7f-bcdc-4784-d106-d680e7259cd5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[12, 23, 4, 27, 3, 18, 3, 2, 34, 14]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assignee target vector to one hot vector"
      ],
      "metadata": {
        "id": "3_S7MrvvyrEh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assignee_tensor = tf.data.Dataset.from_tensor_slices(assignee_vector)\n",
        "assignee_one_hot = assignee_tensor.map(lambda x: tf.one_hot(x, len(assignee_dict)))"
      ],
      "metadata": {
        "id": "q3HC2wei6pKg"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zip descriptions and assignee for training"
      ],
      "metadata": {
        "id": "Upv9A3lIz0yl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.zip((descriptions, assignee_one_hot))"
      ],
      "metadata": {
        "id": "I7nvT4Rn6rF6"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shuffle dataset, set reshuffle_each_iteration=False as this defaults to True and then splits will be different per epoch.\n"
      ],
      "metadata": {
        "id": "vN-uhSuDz525"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_len = len(dataset)\n",
        "dataset = dataset.shuffle(data_len, seed = 42, reshuffle_each_iteration = False)"
      ],
      "metadata": {
        "id": "lnFNdcuw6tDP"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split dataset into train validation and test dataset batch size is 32 and validation and test size is 15%"
      ],
      "metadata": {
        "id": "9bw2vaPW0LSo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "BATCH_SIZE = 32\n",
        "VAL_SIZE = 0.15\n",
        "n_examples = tf.data.experimental.cardinality(dataset).numpy()\n",
        "\n",
        "VAL_SIZE = round(VAL_SIZE*n_examples)\n",
        "test_dataset = dataset.take(VAL_SIZE).batch(batch_size=BATCH_SIZE, drop_remainder=True)\n",
        "val_dataset = dataset.skip(VAL_SIZE).take(VAL_SIZE).batch(batch_size=BATCH_SIZE, drop_remainder=True)\n",
        "train_dataset = dataset.skip(VAL_SIZE*2).batch(batch_size=BATCH_SIZE, drop_remainder=True)"
      ],
      "metadata": {
        "id": "4QYhk6pe6voT"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prefetch train val and test dataset"
      ],
      "metadata": {
        "id": "yEZeAElR0P5X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "val_dataset = val_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "test_dataset = test_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "print('len(train_dataset): # of batches', len(train_dataset))\n",
        "print('len(val_dataset): # of batches', len(val_dataset))\n",
        "print('len(test_dataset): # of batches', len(test_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSJhzYCj6zI_",
        "outputId": "ada37c53-1c97-41a2-bf61-06e10ece2135"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(train_dataset): # of batches 138\n",
            "len(val_dataset): # of batches 29\n",
            "len(test_dataset): # of batches 29\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train dataset examples"
      ],
      "metadata": {
        "id": "zb23x4YG0WRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for input, target in train_dataset.take(1):\n",
        "    print(input)\n",
        "    print(target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYw6d0jw_O3E",
        "outputId": "375e5194-7f2c-4a6a-cc34-da4b0050aef6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'Saw the following stacktrace kafka network thread prio tid fce nid xeefa runnable eef java lang Thread State RUNNABLE at sun nio ch KQueueArrayWrapper kevent Native Method at sun nio ch KQueueArrayWrapper poll KQueueArrayWrapper java at sun nio ch KQueueSelectorImpl doSelect KQueueSelectorImpl java at sun nio ch SelectorImpl lockAndDoSelect SelectorImpl java locked fa a sun nio ch Util locked fa a java util Collections UnmodifiableSet locked fa a sun nio ch KQueueSelectorImpl at sun nio ch SelectorImpl select SelectorImpl java at kafka network Processor run SocketServer scala at java lang Thread run Thread java Test worker prio tid fced nid xc waiting on condition java lang Thread State WAITING parking at sun misc Unsafe park Native Method parking to wait for fad a java util concurrent CountDownLatch Sync at java util concurrent locks LockSupport park LockSupport java at java util concurrent locks AbstractQueuedSynchronizer parkAndCheckInterrupt AbstractQueuedSynchronizer java at java util concurrent '\n",
            " b'The current implementation of Segments used by Rocks Session and Time window stores is in conflict with our current timestamp management model The current segmentation approach allows configuration of a fixed number of segments let s say and a fixed retention time We essentially divide up the retention time into the available number of segments quote expiration date right now retention time seg seg seg seg quote Note that we keep one extra segment so that we can record new events while some events in seg are actually expired but we only drop whole segments so they just get to hang around quote expiration date right now retention time seg seg seg seg quote When it s time to provision segment we know that segment is completely expired so we drop it quote expiration date right now retention time seg seg seg seg quote However the current timestamp management model '\n",
            " b'code java When Trogdor wants to clear all the faults injected to Kibosh it sends the empty JSON object However Kibosh expects faults instead Kibosh should handle the empty JSON object since that s consistent with how Trogdor handles empty JSON fields in general if they re empty they can be omitted We should also have a test for this code '\n",
            " b'When a stream task is being suspended in RecordQueue clear we will clear the ArrayDeque fifoQueue but we do not clear the MinTimestampTracker s maintained list As a result if the task gets resumed we will live with an empty fifoQueue while a populated tracker And hence we use reference equality to check if the smallest timestamp record can be popped we would never be able to pop any more records and hence effectively leading to memory leak '\n",
            " b'Currently we remove the SNAPSHOT marker immediately upon branching Which means that our release artifacts are all released to maven repos with the same version Which is apparently challenging for projects that depend on Kafka to test with the release artifacts We need to revisit discuss and maybe improve the process for the next release '\n",
            " b'From KIP quote Producers and consumers currently expose average and maximum producer fetch request throttle time as JMX metrics These metrics will be updated to reflect total throttle time for the producer or consumer including byte rate throttling and request time throttling for all requests of the producer consumer quote Missed this during the request quota implementation '\n",
            " b'I m porting some unit tests from to The test does the following all embedded in the same java process spins up a zk instance spins up a kafka server using a fresh log directory creates a producer and sends a message creates a high level consumer and verifies that it can consume the message shuts down the consumer stops the kafka server stops zk The test seems to be working fine now however I consistently see the following exception when the consumer connector is shutdown ConsumerFetcherThread group square aac local dbbeb WARN kafka consumer ConsumerFetcherThread ConsumerFetcherThread group square aac local dbbeb Error in fetch Name FetchRequest Version CorrelationId ClientId group ConsumerFetcherThread group square aac local dbbeb ReplicaId MaxWait ms MinBytes bytes RequestInfo test topic PartitionFetchInfo java nio channels ClosedByInterruptException at java nio channels spi AbstractInterruptibleChannel end AbstractInterruptibleChannel java at sun nio ch SocketChannelImpl connect SocketChannelImpl java at kafka network '\n",
            " b'RocksDBStore doesn t keep track of the open iterators So when the store is closed due to rebalance or otherwise this may result in resource leakage as any open iterators will not be closed The store should keep track of the open iterators and close them when the store is closed '\n",
            " b'When creating a simple stream topology to just populate a GlobalKTable I noticed from logging that the stream consumer was doing group coordination requests JoinGroup SyncGroup to the server which it had no reason to do since the global consumer thread populating the table fetches from all partitions and thus doesn t use the group requests So this adds needless overhead on the client network and server I tracked this down to the stream thread consumer which is created regardless of whether it s needed based solely on NUM STREAM THREADS CONFIG which defaults to I guess I found that setting NUM STREAM THREADS CONFIG to will prevent this from happening but it d be a worthwhile improvement to be able to override this setting in cases of topologies like this that don t have any need for stream threads Hence this ticket I originally asked about this on the '\n",
            " b'Saw the following error kafka api ProducerBounceTest testBrokerFailure STANDARD OUT ERROR ReplicaFetcherThread Error due to kafka server ReplicaFetcherThread java lang IllegalMonitorStateException at java util concurrent locks ReentrantLock Sync tryRelease ReentrantLock java at java util concurrent locks AbstractQueuedSynchronizer release AbstractQueuedSynchronizer java at java util concurrent locks AbstractQueuedSynchronizer fullyRelease AbstractQueuedSynchronizer java at java util concurrent locks AbstractQueuedSynchronizer ConditionObject await AbstractQueuedSynchronizer java at kafka server AbstractFetcherThread doWork AbstractFetcherThread scala at kafka utils ShutdownableThread run ShutdownableThread scala ERROR ReplicaFetcherThread Error due to kafka server ReplicaFetcherThread java lang IllegalMonitorStateException at java util concurrent locks ReentrantLock Sync tryRelease ReentrantLock java at java util concurrent locks AbstractQueuedSynchronizer release AbstractQueuedSynchronizer java at java util concurrent locks AbstractQueuedSynchronizer fullyRelease AbstractQueuedSynchronizer java at java util concurrent locks AbstractQueuedSynchronizer ConditionObject await AbstractQueuedSynchronizer java at kafka server AbstractFetcherThread doWork AbstractFetcherThread scala at kafka utils ShutdownableThread run ShutdownableThread scala We should grab the lock before waiting on the condition '\n",
            " b'Refactor kafkatest docker support to fix some issues '\n",
            " b'It makes sense to handle timeout for forwarding request coming from the client instead of retry indefinitely We could either use the api timeout or a customized timeout hook which could be defined by different request types '\n",
            " b'Following on KAFKA Streams needs to handle the new behavior See also https github com apache kafka pull Streams code StreamTask java needs to be modified to handle the new exception From the upstream change commtit abort Transaction can also throw TimeoutException now default MAX BLOCK MS CONFIG in producer is seconds so I think just wrapping it as StreamsException should be reasonable similar to what we do for producer send s TimeoutException https github com apache kafka blob trunk streams src main java org apache kafka streams processor internals RecordCollectorImpl java L L See also https github com apache kafka pull issuecomment '\n",
            " b'Currently the cache stores and accounts for records not bytes or objects This investigation would be around measuring any performance overheads that come from storing bytes or objects As an outcome we should know whether we should store bytes or we should store objects If we store objects the cache still needs to know their size so that it can know if the object fits in the allocated cache space e g if the cache is MB and the object is MB we d have space for such objects The investigation needs to figure out how to find out the size of the object efficiently in Java If we store bytes then we are serialising an object into bytes before caching it i e we take a serialisation cost The investigation needs measure how bad this cost can be especially for the case when all objects fit in cache and '\n",
            " b'This is a follow up to KAFKA which introduced describeConsumerGroup groupId String Map TopicPartition String Map String List TopicPartition It was suggested on the PR to rather have describeConsumerGroup groupId String List ConsumerSummary '\n",
            " b'code Kafka Fetcher for Source source bj docker large INFO org apache kafka clients consumer ConsumerConfig ConsumerConfig values auto commit interval ms auto offset reset latest bootstrap servers check crcs true client id connections max idle ms enable auto commit true exclude internal topics true fetch max bytes fetch max wait ms fetch min bytes group id tcprtdetail flink heartbeat interval ms interceptor classes null key deserializer class org apache kafka common serialization ByteArrayDeserializer max partition fetch bytes max poll interval ms max poll records metadata max age ms metric reporters metrics num samples metrics recording level INFO metrics sample window ms partition assignment strategy class org apache kafka clients consumer RangeAssignor receive buffer bytes reconnect backoff ms request timeout ms retry backoff ms sasl jaas config null sasl kerberos kinit cmd usr bin kinit sasl kerberos min time before relogin sasl kerberos service name null sasl kerberos ticket renew '\n",
            " b'While working on https issues apache org jira browse KAFKA I discovered another bug in Streams when some partitions are corrupted due to offsets out of range we treat it as task corrupted and would close them as dirty and then revive However we forget to overwrite the checkpoint file excluding those out of range partitions to let them be re bootstrapped from the new log start offset and hence when the task is revived it would still load the old offset and start from there and then get the out of range exception again This may cause StreamsUpgradeTest test app upgrade to be flaky We do not see this often because in the past we always delete the checkpoint file after loading it and we usually only see the out of range exception at the beginning of the restoration but not during restoration '\n",
            " b'code test id kafkatest tests streams streams smoke test StreamsSmokeTest test streamsstatus FAILrun time minutes seconds Traceback most recent call last File var lib jenkins workspace system test kafka kafka venv local lib python site packages ducktape py egg ducktape tests runner client py line in run data self run test File var lib jenkins workspace system test kafka kafka venv local lib python site packages ducktape py egg ducktape tests runner client py line in run test return self test context function self test File var lib jenkins workspace system test kafka kafka tests kafkatest tests streams streams smoke test py line in test streams node account ssh grep SUCCESS s self driver STDOUT FILE allow fail False File var lib jenkins workspace system test kafka kafka venv local lib python site packages ducktape py egg ducktape cluster remoteaccount py line in ssh raise RemoteCommandError self cmd exit status '\n",
            " b'Implement a system test that creates network partitions '\n",
            " b'It is often helpful to have the batch level information when deep iterating a segment Currently you have to run DumpLogSegments with and without deep iteration and then correlate the results It would be simpler to print both We could even nest the individual messages to make the batch boundaries clear For example code baseOffset lastOffset magic position offset keysize offset keysize baseOffset lastOffset magic position offset keysize offset keysize offset keysize code '\n",
            " b'JMX metric for kafka network type RequestMetrics name RequestsPerSec request Produce seems to require the API version by adding version at the end of JMX metric name noformat badai Badai Aqrandista MBP bin kafka run class kafka tools JmxTool jmx url service jmx rmi jndi rmi jmxrmi object name kafka network type RequestMetrics name RequestsPerSec request Produce Trying to connect to JMX url service jmx rmi jndi rmi jmxrmi No matched attributes for the queried objects ArrayBuffer kafka network type RequestMetrics name RequestsPerSec request Produce noformat noformat badai Badai Aqrandista MBP bin kafka run class kafka tools JmxTool jmx url service jmx rmi jndi rmi jmxrmi object name kafka network type RequestMetrics name RequestsPerSec request Produce version Trying to connect to JMX url service jmx rmi jndi rmi jmxrmi time kafka network type RequestMetrics name RequestsPerSec request Produce version Count kafka network type RequestMetrics name RequestsPerSec request Produce version EventType '\n",
            " b'When setting batch size to for producer I get the following exception when sending a record noformat java lang NullPointerException at org apache kafka common utils Utils notNull Utils java at org apache kafka clients producer internals RecordAccumulator append RecordAccumulator java at org apache kafka clients producer KafkaProducer doSend KafkaProducer java at org apache kafka clients producer KafkaProducer send KafkaProducer java at org apache kafka clients producer KafkaProducer send KafkaProducer java at KafkaProducerTest exposeNpeOnBatchSizeZero KafkaProducerTest java noformat But documentation says quote a batch size of zero will disable batching entirely quote Please see attached test '\n",
            " b'We need to get system test coverage for the new consumer implementation and the co ordinator '\n",
            " b'KafkaAdminClient describeAcls should handle invalid filters gracefully Specifically it should return a future which yields an exception The following code results in an uncaught IllegalArgumentException in the admin client thread resulting in a zombie admin client code AclBindingFilter aclFilter new AclBindingFilter new ResourcePatternFilter ResourceType UNKNOWN null PatternType ANY AccessControlEntryFilter ANY kafkaAdminClient describeAcls aclFilter values get code See the resulting stacktrace below code ERROR kafka admin client thread adminclient Uncaught exception in thread kafka admin client thread adminclient org apache kafka common utils KafkaThread java lang IllegalArgumentException Filter contain UNKNOWN elements at org apache kafka common requests DescribeAclsRequest validate DescribeAclsRequest java at org apache kafka common requests DescribeAclsRequest init DescribeAclsRequest java at org apache kafka common requests DescribeAclsRequest Builder build DescribeAclsRequest java at org apache kafka common requests DescribeAclsRequest Builder build DescribeAclsRequest java at org apache kafka clients NetworkClient doSend NetworkClient java at org apache kafka clients NetworkClient send NetworkClient java '\n",
            " b'Hi We recently had a kafka node go down suddenly When it came back up it apparently had a corrupt recovery file and refused to startup code WARN main server KafkaServer Error starting up KafkaServerjava lang NumberFormatException For input string at java lang NumberFormatException forInputString NumberFormatException java at java lang Integer parseInt Integer java at java lang Integer parseInt Integer java at scala collection immutable StringLike class toInt StringLike scala at scala collection immutable StringOps toInt StringOps scala at kafka server OffsetCheckpoint read OffsetCheckpoint scala at kafka log LogManager anonfun loadLogs apply LogManager scala at kafka log LogManager anonfun loadLogs apply LogManager scala at scala collection IndexedSeqOptimized class foreach IndexedSeqOptimized scala at scala collection mutable WrappedArray foreach WrappedArray scala at kafka log LogManager loadLogs LogManager scala at kafka log LogManager init LogManager scala at kafka server KafkaServer createLogManager KafkaServer scala at kafka server KafkaServer startup KafkaServer scala code And the '\n",
            " b'Source task offset commits take place on a dedicated thread which periodically triggers offset commits for all of the source tasks on the worker on a user configurable interval and with a user configurable timeout for each offset commit When a task fails offset commits continue to take place In the common case where there is no longer any chance for another successful offset commit for the task this has two negative side effects First confusing log messages are emitted that some users reasonably interpret as a sign that the source task is still alive noformat INFO WorkerSourceTask id Salesforce PC Connector Agency Committing offsets org apache kafka connect runtime WorkerSourceTask INFO WorkerSourceTask id Salesforce PC Connector Agency flushing outstanding messages for offset commit org apache kafka connect runtime WorkerSourceTask noformat Second if the task has any source records pending it will block the shared offset commit thread until the '\n",
            " b'Since https issues apache org jira browse KAFKA chroot pass is created on startup So the description quoted below is wrong bq Note that you must create this path yourself prior to starting the brokercf http mail archives apache org mod mbox kafka users mbox CCAHBVWcjXeUnEHKGZ f kPGJM DC DPaAuiOSGdxcAsgg mail gmail com E '\n",
            " b'We only track request queue size of the socket server However when response send time is high it is useful to know the response queue sizes as well '\n",
            " b'Currently the consumer reports a metric of the lag between the high watermark of a log and the consumer offset It will be useful to report a similar lag metric between the consumer offset and the start offset of the log If this latter lag gets close to it s an indication that the consumer may lose data soon '\n",
            " b'I didn t have my truststore set up correctly The Kafka producer waited until the connection timed out seconds in my case and then threw this exception code Exception in thread main java util concurrent ExecutionException org apache kafka common errors TimeoutException Failed to update metadata after ms at org apache kafka clients producer KafkaProducer FutureFailure init KafkaProducer java at org apache kafka clients producer KafkaProducer send KafkaProducer java at org apache kafka clients producer KafkaProducer send KafkaProducer java code I changed my log level to DEBUG and found this less than two seconds after startup code DEBUG User Server Client URL ChangeGroup org apache kafka common network Selector Connection with kafka disconnected javax net ssl SSLHandshakeException General SSLEngine problem at sun security ssl Handshaker checkThrown Handshaker java at sun security ssl SSLEngineImpl checkTaskThrown SSLEngineImpl java at sun security ssl SSLEngineImpl writeAppRecord SSLEngineImpl java at sun security ssl SSLEngineImpl wrap '\n",
            " b'It behaves better on Windows and provides more useful error messages '\n",
            " b'We have just updated our testing Kafka cluster to and we were facing one issue with migration of legacy configuration to noformat listeners PLAINTEXT advertised listeners PLAINTEXT myPublicHostName REQUIRED for noformat This configuration will be invalid if advertised listeners is not set too Connection string is stored to ZooKeeper according to documentation of advertised listeners and observed behavior but it isn t obvious and difficult to analyze Clients and even other brokers try to communicate with brokers using destination address which is impossible Specification of advertised listeners as shown above fixed the issue Please update documentation at http kafka apache org documentation brokerconfigs and backport the change to and branches h advertised listenersListeners to publish to ZooKeeper for clients to use if different than the listeners above In IaaS environments this may need to be different from the interface to which the broker binds If this is not set the '], shape=(32,), dtype=string)\n",
            "tf.Tensor(\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 1.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]], shape=(32, 36), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bag-of-Words Implementation"
      ],
      "metadata": {
        "id": "rWCswIQT0nSW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating input vectorizer so that given a string vectorizer maps it to a bag of words vector "
      ],
      "metadata": {
        "id": "zzUKwjIY0v8k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_vectorizer = layers.TextVectorization(\n",
        "    split = \"whitespace\",\n",
        "    standardize = 'lower_and_strip_punctuation',\n",
        "    output_mode='multi_hot')"
      ],
      "metadata": {
        "id": "VihPoX2j7ji0"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adapting input vectorizer with our datasets, vectorizer learns the vocabulary from the dataset "
      ],
      "metadata": {
        "id": "wP88AEhZ04w2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_vectorizer.adapt(descriptions)"
      ],
      "metadata": {
        "id": "taauvLwl7obt"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our vocabulary consists of 13897 words"
      ],
      "metadata": {
        "id": "Yj-2pJzh1BKh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(input_vectorizer.get_vocabulary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hX5KJ_nWqnGR",
        "outputId": "2efe7b45-3821-462b-c19f-6333b6966c8c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13897"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pickle the config and weights"
      ],
      "metadata": {
        "id": "Z0qO0cVv1GoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " \n",
        "'''\n",
        "pickle.dump({'config': input_vectorizer.get_config(),\n",
        "             'weights': input_vectorizer.get_weights()}\n",
        "            , open(save_path + \"input_vectorizer.pkl\", \"wb\"))\n",
        "'''"
      ],
      "metadata": {
        "id": "aQ13xZueidNh"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "An example of input vectorizer with a description and it's vectorizer result"
      ],
      "metadata": {
        "id": "MD1vF5pz1NyG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for description in descriptions.take(2):\n",
        "    print(description)\n",
        "    print(input_vectorizer(description))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oB21dZwI7u0P",
        "outputId": "8fd07211-bf0e-4c30-cbcc-8da351720e7a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b'code java java util concurrent ExecutionException org apache kafka common errors UnknownTopicOrPartitionException This server does not host this topic partition at org apache kafka common internals KafkaFutureImpl wrapAndThrow KafkaFutureImpl java at org apache kafka common internals KafkaFutureImpl access KafkaFutureImpl java at org apache kafka common internals KafkaFutureImpl SingleWaiter await KafkaFutureImpl java at org apache kafka common internals KafkaFutureImpl get KafkaFutureImpl java at kafka api SaslSslAdminClientIntegrationTest testCreateTopicsResponseMetadataAndConfig SaslSslAdminClientIntegrationTest scala at sun reflect NativeMethodAccessorImpl invoke Native Method at sun reflect NativeMethodAccessorImpl invoke NativeMethodAccessorImpl java at sun reflect DelegatingMethodAccessorImpl invoke DelegatingMethodAccessorImpl java at java lang reflect Method invoke Method java at org junit runners model FrameworkMethod runReflectiveCall FrameworkMethod java at org junit internal runners model ReflectiveCallable run ReflectiveCallable java at org junit runners model FrameworkMethod invokeExplosively FrameworkMethod java at org junit internal runners statements InvokeMethod evaluate InvokeMethod java at org junit internal runners statements RunBefores evaluate RunBefores java at org junit internal runners ', shape=(), dtype=string)\n",
            "tf.Tensor([0. 0. 0. ... 0. 0. 0.], shape=(13897,), dtype=float32)\n",
            "tf.Tensor(b'I found this problem while investigating KAFKA Some broker wide configurations defined in KafkaConfig are mapped with log wide configurations defined in LogConfig providing a default value You can find the complete mapping list in LogConfig TopicConfigSynonyms The problem is some configuration properties validation is different between KafkaConfig and LogConfig png These inconsistencies cause some problems with the dynamic configuration feature When a user dynamically configures the broker configuration with AdminClient alterConfigs the submitted config is validated with KafkaConfig which lacks some validation logic as a result they bypasses the correct validation For example a user can set log cleaner min cleanable ratio to which is obviously prohibited in LogConfig I could not reproduce the situation KAFKA describes but fixing this problem also resolves KAFKA ', shape=(), dtype=string)\n",
            "tf.Tensor([0. 1. 1. ... 0. 0. 0.], shape=(13897,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vectorizing whole dataset (descriptions, assignees) so that we can feed it into neural networks"
      ],
      "metadata": {
        "id": "J9F4A3KQ1hyK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorize_dataset(description, assignee):\n",
        "\n",
        "  return input_vectorizer(description), assignee\n",
        "\n",
        "bow_train_dataset = train_dataset.map(vectorize_dataset)\n",
        "bow_val_dataset = val_dataset.map(vectorize_dataset)\n",
        "bow_test_dataset = test_dataset.map(vectorize_dataset)\n",
        "for description, assignee in bow_train_dataset.take(1):\n",
        "    print(description, assignee)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEIpcFxh9uSE",
        "outputId": "37cf222e-87fd-47d5-9aeb-d3018e09e5ef"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[0. 1. 1. ... 0. 0. 0.]\n",
            " [0. 1. 1. ... 0. 0. 0.]\n",
            " [0. 1. 1. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 1. 1. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 1. 1. ... 0. 0. 0.]], shape=(32, 13897), dtype=float32) tf.Tensor(\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 1.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]], shape=(32, 36), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating early stopping to prevent overfitting to training data"
      ],
      "metadata": {
        "id": "_wWPPYNp1rMW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs\")\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)"
      ],
      "metadata": {
        "id": "uzd0Nlka-k4p"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Very simple bag of words model that consists of one hidden layer with 64 nodes, one dropout layer and one prediction layer"
      ],
      "metadata": {
        "id": "ZK3Qp1ET1ym-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = input_vectorizer.vocabulary_size()\n",
        "bow_model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(64, kernel_regularizer=regularizers.l2(0.05),input_shape=(vocab_size,), activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.5),\n",
        "  tf.keras.layers.Dense(len(assignee_dict), activation = \"softmax\")\n",
        "])"
      ],
      "metadata": {
        "id": "Jr-46PX_-Dw6"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compiling bow_model with an optimizer, loss and metric"
      ],
      "metadata": {
        "id": "xn-W5is219v0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bow_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.1),\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "              metrics = tf.keras.metrics.CategoricalAccuracy()\n",
        ")"
      ],
      "metadata": {
        "id": "V8hqE5BY-SOQ"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary of bow_model"
      ],
      "metadata": {
        "id": "ZLfvl5mp2C2b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bow_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvxJEht1-W8S",
        "outputId": "b70ac6b5-6925-4c0d-e21d-8679a5863c9f"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 64)                889472    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 36)                2340      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 891,812\n",
            "Trainable params: 891,812\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training bow_model"
      ],
      "metadata": {
        "id": "65niOUIG2I0C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bow_model.fit(\n",
        "    bow_train_dataset,\n",
        "    validation_data=bow_val_dataset,\n",
        "    epochs=20,\n",
        "    callbacks=[tensorboard_callback,callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVGi5j65z9wK",
        "outputId": "77b4581a-03cc-4d65-fb0b-20fe568cd597"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "138/138 [==============================] - 2s 8ms/step - loss: 5.6613 - categorical_accuracy: 0.0856 - val_loss: 3.8136 - val_categorical_accuracy: 0.0916\n",
            "Epoch 2/20\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 3.5359 - categorical_accuracy: 0.1259 - val_loss: 3.4232 - val_categorical_accuracy: 0.1110\n",
            "Epoch 3/20\n",
            "138/138 [==============================] - 1s 8ms/step - loss: 3.3731 - categorical_accuracy: 0.1510 - val_loss: 3.3744 - val_categorical_accuracy: 0.1659\n",
            "Epoch 4/20\n",
            "138/138 [==============================] - 1s 8ms/step - loss: 3.3469 - categorical_accuracy: 0.1655 - val_loss: 3.3545 - val_categorical_accuracy: 0.1886\n",
            "Epoch 5/20\n",
            "138/138 [==============================] - 3s 19ms/step - loss: 3.3341 - categorical_accuracy: 0.1800 - val_loss: 3.3380 - val_categorical_accuracy: 0.1789\n",
            "Epoch 6/20\n",
            "138/138 [==============================] - 1s 8ms/step - loss: 3.3283 - categorical_accuracy: 0.1873 - val_loss: 3.3294 - val_categorical_accuracy: 0.1886\n",
            "Epoch 7/20\n",
            "138/138 [==============================] - 1s 8ms/step - loss: 3.2951 - categorical_accuracy: 0.1993 - val_loss: 3.3105 - val_categorical_accuracy: 0.2058\n",
            "Epoch 8/20\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 3.2904 - categorical_accuracy: 0.2065 - val_loss: 3.2906 - val_categorical_accuracy: 0.2177\n",
            "Epoch 9/20\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 3.2802 - categorical_accuracy: 0.2099 - val_loss: 3.2924 - val_categorical_accuracy: 0.2112\n",
            "Epoch 10/20\n",
            "138/138 [==============================] - 1s 8ms/step - loss: 3.2804 - categorical_accuracy: 0.2185 - val_loss: 3.2774 - val_categorical_accuracy: 0.2349\n",
            "Epoch 11/20\n",
            "138/138 [==============================] - 1s 8ms/step - loss: 3.2651 - categorical_accuracy: 0.2185 - val_loss: 3.2730 - val_categorical_accuracy: 0.2306\n",
            "Epoch 12/20\n",
            "138/138 [==============================] - 2s 12ms/step - loss: 3.2646 - categorical_accuracy: 0.2237 - val_loss: 3.2864 - val_categorical_accuracy: 0.2101\n",
            "Epoch 13/20\n",
            "138/138 [==============================] - 2s 12ms/step - loss: 3.2573 - categorical_accuracy: 0.2314 - val_loss: 3.2599 - val_categorical_accuracy: 0.2457\n",
            "Epoch 14/20\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 3.2649 - categorical_accuracy: 0.2298 - val_loss: 3.2609 - val_categorical_accuracy: 0.2414\n",
            "Epoch 15/20\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 3.2659 - categorical_accuracy: 0.2296 - val_loss: 3.2476 - val_categorical_accuracy: 0.2522\n",
            "Epoch 16/20\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 3.2356 - categorical_accuracy: 0.2351 - val_loss: 3.2414 - val_categorical_accuracy: 0.2338\n",
            "Epoch 17/20\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 3.2485 - categorical_accuracy: 0.2418 - val_loss: 3.2505 - val_categorical_accuracy: 0.2489\n",
            "Epoch 18/20\n",
            "138/138 [==============================] - 1s 8ms/step - loss: 3.2429 - categorical_accuracy: 0.2428 - val_loss: 3.2400 - val_categorical_accuracy: 0.2629\n",
            "Epoch 19/20\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 3.2513 - categorical_accuracy: 0.2439 - val_loss: 3.2512 - val_categorical_accuracy: 0.2586\n",
            "Epoch 20/20\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 3.2450 - categorical_accuracy: 0.2416 - val_loss: 3.2442 - val_categorical_accuracy: 0.2554\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbf58a9c450>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing bow_model on test dataset"
      ],
      "metadata": {
        "id": "sxpKDhg52WdW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = bow_model.evaluate(bow_test_dataset)\n",
        "\n",
        "print(f'Loss: {loss}')\n",
        "print(f'Accuracy: {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccBl_mzZXKXJ",
        "outputId": "d2ed63a0-3269-4358-8c4d-62f71c3e3cbd"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29/29 [==============================] - 0s 4ms/step - loss: 3.2011 - categorical_accuracy: 0.2683\n",
            "Loss: 3.2010693550109863\n",
            "Accuracy: 0.26831895112991333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving bow_model to reload and use in demo notebook"
      ],
      "metadata": {
        "id": "EScGr6dW2uCa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "saved_model_path = model_save_path + '/bow_model_3'"
      ],
      "metadata": {
        "id": "pwTlhZrxFo_w"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bow_model.save(saved_model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7v0V3IK4FlVA",
        "outputId": "e962b851-d956-436d-c504-5476def510e8"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks//bow_model_3/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks//bow_model_3/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# bidirectional LSTM (BiLSTM) with recurrent neural network (RNN) architecture"
      ],
      "metadata": {
        "id": "SuDmDkdl25Pd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "P_0DMbSP6lkC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize a TextVectorization layer for word embedding with the desired parameters"
      ],
      "metadata": {
        "id": "7Xhqkhj-5F_0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = 10000\n",
        "encoder = tf.keras.layers.TextVectorization(\n",
        "    max_tokens=VOCAB_SIZE)\n",
        "encoder.adapt(train_dataset.map(lambda text, label: text))"
      ],
      "metadata": {
        "id": "gWTPiSWYEmH2"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some examples from vocabulary"
      ],
      "metadata": {
        "id": "Zwlrl5sX55la"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = np.array(encoder.get_vocabulary())\n",
        "vocab[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffaff2c6-c0b0-4b72-fee4-87d1eebf374e",
        "id": "cXJlDGZZEmH2"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['', '[UNK]', 'the', 'to', 'kafka', 'a', 'at', 'is', 'in', 'java',\n",
              "       'and', 'of', 'org', 'this', 'we', 'apache', 'for', 'it', 'that',\n",
              "       'scala', 'be', 'not', 'consumer', 'with', 'topic', 'on', 'code',\n",
              "       'are', 'if', 'when', 'i', 'as', 'from', 'test', 'log', 'will',\n",
              "       'streams', 'should', 'error', 'producer', 'can', 'broker', 'have',\n",
              "       'but', 'partition', 'an', 'https', 'new', 'by', 'which', 's', 't',\n",
              "       'server', 'clients', 'thread', 'all', 'state', 'connect', 'or',\n",
              "       'request', 'message', 'internals', 'offset', 'there', 'common',\n",
              "       'would', 'junit', 'one', 'time', 'config', 'was', 'lang', 'some',\n",
              "       'group', 'use', 'so', 'partitions', 'only', 'run', 'data',\n",
              "       'currently', 'com', 'kip', 'has', 'client', 'since', 'api',\n",
              "       'messages', 'exception', 'class', 'no', 'leader', 'assert', 'id',\n",
              "       'collection', 'after', 'topics', 'value', 'using', 'following'],\n",
              "      dtype='<U255')"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initializing BiLSTM model with using two bidirectional LSTM layers"
      ],
      "metadata": {
        "id": "p0cBFkbL58yc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_model = tf.keras.Sequential([\n",
        "    encoder,\n",
        "    tf.keras.layers.Embedding(\n",
        "        input_dim=len(encoder.get_vocabulary()),\n",
        "        output_dim=64,\n",
        "        # Use masking to handle the variable sequence lengths\n",
        "        mask_zero=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, dropout=0.2, return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32,dropout=0.2)),\n",
        "    tf.keras.layers.Dense(len(assignee_dict))\n",
        "])"
      ],
      "metadata": {
        "id": "7eGXxgKVEmH3"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RNN with BiLSTM model Summary"
      ],
      "metadata": {
        "id": "ALMaLDNe6gl_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(rnn_model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79d24085-13fc-4e4b-ae9e-5ae52ec0ec8b",
        "id": "iX7BGuznEmH3"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " text_vectorization_1 (TextV  (None, None)             0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, None, 64)          640000    \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirectio  (None, None, 128)        66048     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirectio  (None, 64)               41216     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 36)                2340      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 749,604\n",
            "Trainable params: 749,604\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compiling RNN model with BiLSTM layers"
      ],
      "metadata": {
        "id": "EdemrsED6iq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_model.compile(loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "uI0wVnQIEmH4"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = rnn_model.fit(train_dataset, epochs=20,\n",
        "                    validation_data=val_dataset,\n",
        "                    callbacks = [callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c155fe2b-43a8-453b-fe0d-e196611df6fd",
        "id": "RscLkvajEmH4"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "138/138 [==============================] - 44s 184ms/step - loss: 3.4225 - accuracy: 0.0913 - val_loss: 3.3631 - val_accuracy: 0.1110\n",
            "Epoch 2/20\n",
            "138/138 [==============================] - 20s 144ms/step - loss: 3.0565 - accuracy: 0.1667 - val_loss: 3.0287 - val_accuracy: 0.1735\n",
            "Epoch 3/20\n",
            "138/138 [==============================] - 20s 144ms/step - loss: 2.4920 - accuracy: 0.3030 - val_loss: 2.8134 - val_accuracy: 0.2338\n",
            "Epoch 4/20\n",
            "138/138 [==============================] - 20s 145ms/step - loss: 1.9975 - accuracy: 0.4380 - val_loss: 2.6902 - val_accuracy: 0.2802\n",
            "Epoch 5/20\n",
            "138/138 [==============================] - 20s 144ms/step - loss: 1.5897 - accuracy: 0.5587 - val_loss: 2.6146 - val_accuracy: 0.3438\n",
            "Epoch 6/20\n",
            "138/138 [==============================] - 20s 143ms/step - loss: 1.2722 - accuracy: 0.6445 - val_loss: 2.7120 - val_accuracy: 0.3750\n",
            "Epoch 7/20\n",
            "138/138 [==============================] - 20s 145ms/step - loss: 0.9935 - accuracy: 0.7271 - val_loss: 2.6321 - val_accuracy: 0.4224\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluating our RNN model with BiLSTM layers on test dataset"
      ],
      "metadata": {
        "id": "YjySXNQu7EX5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = rnn_model.evaluate(test_dataset)\n",
        "\n",
        "print(f'Loss: {loss}')\n",
        "print(f'Accuracy: {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b73e3437-b599-4e7e-c9b9-4f3b7e07e77c",
        "id": "dUcLQm0dEmH4"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29/29 [==============================] - 2s 52ms/step - loss: 2.5828 - accuracy: 0.4138\n",
            "Loss: 2.582845449447632\n",
            "Accuracy: 0.4137931168079376\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving the model"
      ],
      "metadata": {
        "id": "b61yqw4A7Jrx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "saved_model_path = model_save_path + '/rnn_model_3'"
      ],
      "metadata": {
        "id": "zfQTMs0yGTD7"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_model.save(saved_model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cefe4407-66ee-4ba8-dc16-33b77e12340e",
        "id": "LwcqTStgGTD8"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_14_layer_call_fn, lstm_cell_14_layer_call_and_return_conditional_losses, lstm_cell_16_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks//rnn_model_3/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks//rnn_model_3/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7fbf4f580a50> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7fbf4f5827d0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7fbf8ae4a290> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7fbf4f599790> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"
      ],
      "metadata": {
        "id": "4g2wbkoJ7QtO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Selecting BERT and preprocess model from [TensorFlow Hub](https://www.tensorflow.org/hub). I preferred the simpler one with _L-2_H-128_A-2, which means 2 layers, 128 dim representations and 2 Attention heads. "
      ],
      "metadata": {
        "id": "M42N-KQK7aaP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model_name = 'small_bert/bert_en_uncased_L-2_H-128_A-2' \n",
        "\n",
        "map_name_to_handle = {\n",
        "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/2',\n",
        "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1'}\n",
        "\n",
        "map_model_to_preprocess = {\n",
        "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'}\n",
        "\n",
        "# find more models and preprocessing maps at \n",
        "# https://www.tensorflow.org/text/tutorials/classify_text_with_bert?hl=en\n",
        "\n",
        "tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
        "tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n",
        "\n",
        "print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
        "print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')\n",
        "\n",
        "\n",
        "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)\n",
        "bert_model = hub.KerasLayer(tfhub_handle_encoder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e49jdDjf-9KH",
        "outputId": "8535ea61-82b1-4e1a-d76b-02f7e1f94cab"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/2\n",
            "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing examples"
      ],
      "metadata": {
        "id": "0-yIj51J8UNd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "text_test = [input[0].numpy(), input[1].numpy()]\n",
        "text_preprocessed = bert_preprocess_model(text_test)\n",
        "\n",
        "print(f'Lines      : {text_test}')\n",
        "print(f'Keys       : {list(text_preprocessed.keys())}')\n",
        "print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
        "print(f'Word Ids   :')\n",
        "print(f'{text_preprocessed[\"input_word_ids\"][:, :12]}')\n",
        "print(f'Input Mask :')\n",
        "print(f'{text_preprocessed[\"input_mask\"][:, :12]}')\n",
        "print(f'Type Ids   :')\n",
        "print(f'{text_preprocessed[\"input_type_ids\"][:, :12]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIPVblxB--cZ",
        "outputId": "88beb9b5-c4af-43ea-ae17-febc208c2a43"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lines      : [b'Saw the following stacktrace kafka network thread prio tid fce nid xeefa runnable eef java lang Thread State RUNNABLE at sun nio ch KQueueArrayWrapper kevent Native Method at sun nio ch KQueueArrayWrapper poll KQueueArrayWrapper java at sun nio ch KQueueSelectorImpl doSelect KQueueSelectorImpl java at sun nio ch SelectorImpl lockAndDoSelect SelectorImpl java locked fa a sun nio ch Util locked fa a java util Collections UnmodifiableSet locked fa a sun nio ch KQueueSelectorImpl at sun nio ch SelectorImpl select SelectorImpl java at kafka network Processor run SocketServer scala at java lang Thread run Thread java Test worker prio tid fced nid xc waiting on condition java lang Thread State WAITING parking at sun misc Unsafe park Native Method parking to wait for fad a java util concurrent CountDownLatch Sync at java util concurrent locks LockSupport park LockSupport java at java util concurrent locks AbstractQueuedSynchronizer parkAndCheckInterrupt AbstractQueuedSynchronizer java at java util concurrent ', b'The current implementation of Segments used by Rocks Session and Time window stores is in conflict with our current timestamp management model The current segmentation approach allows configuration of a fixed number of segments let s say and a fixed retention time We essentially divide up the retention time into the available number of segments quote expiration date right now retention time seg seg seg seg quote Note that we keep one extra segment so that we can record new events while some events in seg are actually expired but we only drop whole segments so they just get to hang around quote expiration date right now retention time seg seg seg seg quote When it s time to provision segment we know that segment is completely expired so we drop it quote expiration date right now retention time seg seg seg seg quote However the current timestamp management model ']\n",
            "Keys       : ['input_mask', 'input_type_ids', 'input_word_ids']\n",
            "Shape      : (2, 128)\n",
            "Word Ids   :\n",
            "[[  101  2387  1996  2206  9991  6494  3401 10556 24316  2050  2897 11689]\n",
            " [  101  1996  2783  7375  1997  9214  2109  2011  5749  5219  1998  2051]]\n",
            "Input Mask :\n",
            "[[1 1 1 1 1 1 1 1 1 1 1 1]\n",
            " [1 1 1 1 1 1 1 1 1 1 1 1]]\n",
            "Type Ids   :\n",
            "[[0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model output examples before training with our dataset"
      ],
      "metadata": {
        "id": "du56UB1_8YuM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "bert_results = bert_model(text_preprocessed)\n",
        "\n",
        "print(f'Loaded BERT: {tfhub_handle_encoder}')\n",
        "print(f'Sequence Outputs Shape:{bert_results[\"sequence_output\"].shape}')\n",
        "print(f'Sequence Outputs Values:{bert_results[\"sequence_output\"][0, :12]}')\n",
        "print(f'Pooled Outputs Shape:{bert_results[\"pooled_output\"].shape}')\n",
        "print(f'Pooled Outputs Values:{bert_results[\"pooled_output\"][0, :12]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbLJyFPp_BzY",
        "outputId": "364a6095-b17e-4c71-8c85-258acd94f97b"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded BERT: https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/2\n",
            "Sequence Outputs Shape:(2, 128, 128)\n",
            "Sequence Outputs Values:[[-0.7978706  -0.39245942 -3.112212   ... -1.196876   -1.7813495\n",
            "   0.89129806]\n",
            " [-1.0537355  -0.27181557  0.3092998  ... -1.6049153  -3.1087265\n",
            "   0.96863866]\n",
            " [-1.3172263   0.6885311   0.11612162 ... -1.9693499  -1.795817\n",
            "   0.73868644]\n",
            " ...\n",
            " [-0.07454477  0.3055162   0.5694753  ... -2.7664793  -0.6082494\n",
            "   1.6092896 ]\n",
            " [-0.1131182  -0.06081036  0.34595737 ... -2.9312954  -2.263903\n",
            "   2.9446657 ]\n",
            " [ 0.52549523 -0.61103     0.01515445 ... -2.4205444  -2.1981342\n",
            "   1.6228845 ]]\n",
            "Pooled Outputs Shape:(2, 128)\n",
            "Pooled Outputs Values:[-0.99925137  0.09567033  0.4052936  -0.725472   -0.53752947  0.05948785\n",
            " -0.02080893 -0.8750553  -0.03955572  0.2193361   0.64436907  0.02810927]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERT classifier Model"
      ],
      "metadata": {
        "id": "lipXWkfy8efU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_bert_classifier_model():\n",
        "  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "  preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
        "  encoder_inputs = preprocessing_layer(text_input)\n",
        "  encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
        "  outputs = encoder(encoder_inputs)\n",
        "  net = outputs['pooled_output'] \n",
        "  net = tf.keras.layers.Dropout(0.5, name = 'dropout_1')(net)\n",
        "  net = tf.keras.layers.Dense(len(assignee_dict), activation=None, name='classifier')(net)\n",
        "  return tf.keras.Model(text_input, net)"
      ],
      "metadata": {
        "id": "7WalvzYV_czh"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building the classifier and its summary"
      ],
      "metadata": {
        "id": "mL5nLQIU8h1S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "bert_bug_assignee_classifier = build_bert_classifier_model()\n",
        "\n",
        "bert_bug_assignee_classifier.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5t4KLzw_grk",
        "outputId": "825c4ef3-84b6-40ab-e9b0-56dc749d9abf"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " text (InputLayer)              [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " preprocessing (KerasLayer)     {'input_mask': (Non  0           ['text[0][0]']                   \n",
            "                                e, 128),                                                          \n",
            "                                 'input_word_ids':                                                \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_type_ids':                                                \n",
            "                                (None, 128)}                                                      \n",
            "                                                                                                  \n",
            " BERT_encoder (KerasLayer)      {'default': (None,   4385921     ['preprocessing[0][0]',          \n",
            "                                128),                             'preprocessing[0][1]',          \n",
            "                                 'sequence_output':               'preprocessing[0][2]']          \n",
            "                                 (None, 128, 128),                                                \n",
            "                                 'pooled_output': (                                               \n",
            "                                None, 128),                                                       \n",
            "                                 'encoder_outputs':                                               \n",
            "                                 [(None, 128, 128),                                               \n",
            "                                 (None, 128, 128)]}                                               \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 128)          0           ['BERT_encoder[0][3]']           \n",
            "                                                                                                  \n",
            " classifier (Dense)             (None, 36)           4644        ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,390,565\n",
            "Trainable params: 4,390,564\n",
            "Non-trainable params: 1\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classifier output examples before training"
      ],
      "metadata": {
        "id": "xbvUIX6M8lm0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "bert_raw_result = bert_bug_assignee_classifier(tf.constant(text_test))\n",
        "print(tf.nn.softmax(bert_raw_result))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dl-PMlZ_liJ",
        "outputId": "46ef4e32-7b37-4f10-d48f-9a9ea22d1dda"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[0.00461664 0.07849946 0.01016529 0.01397957 0.01025757 0.01672038\n",
            "  0.00616649 0.0613345  0.01570095 0.00954723 0.01022766 0.01668776\n",
            "  0.0139678  0.02163674 0.01842308 0.00338146 0.00806365 0.03490677\n",
            "  0.01189775 0.06619357 0.01798718 0.05329616 0.02640694 0.05112782\n",
            "  0.01086289 0.07753524 0.01285555 0.10941197 0.0191719  0.00705469\n",
            "  0.08049639 0.01318844 0.04913106 0.01021915 0.00930987 0.0195704 ]\n",
            " [0.00705634 0.02845198 0.0245383  0.02295719 0.04416997 0.01461216\n",
            "  0.00628969 0.09558216 0.01008123 0.01466828 0.02309811 0.01269863\n",
            "  0.01995655 0.01190472 0.00750264 0.01272508 0.0160588  0.03536161\n",
            "  0.00775232 0.12998621 0.00659966 0.04150823 0.05348043 0.0212934\n",
            "  0.03240777 0.01298452 0.0223408  0.06290666 0.03599936 0.01287823\n",
            "  0.05152658 0.01477064 0.01505962 0.02538559 0.02499449 0.02041201]], shape=(2, 36), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting the BERT model"
      ],
      "metadata": {
        "id": "u2SLELtD8p2v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tf.keras.utils.plot_model(bert_bug_assignee_classifier)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "u_S22__Z_ozW",
        "outputId": "5350fee1-f204-484a-bb1e-8546db0a4b3b"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating optimizer, loss, metrics and then compiling the BERT classifier"
      ],
      "metadata": {
        "id": "W_EIcIyd8w17"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 15\n",
        "steps_per_epoch = tf.data.experimental.cardinality(train_dataset).numpy()\n",
        "num_train_steps = steps_per_epoch * epochs\n",
        "\n",
        "# Here we are using AdamW with a linear learning rate schedule.\n",
        "# Because of the rolling averages in the optimization logic we need a few warm up steps.\n",
        "warmup_ratio = 0.1\n",
        "num_warmup_steps = int(warmup_ratio*num_train_steps)\n",
        "init_lr = 1e-3\n",
        "\n",
        "print('steps per epoch',steps_per_epoch)\n",
        "print('num train',num_train_steps)\n",
        "print('num warmup',num_warmup_steps)\n",
        "\n",
        "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
        "                                          num_train_steps=num_train_steps,\n",
        "                                          num_warmup_steps=num_warmup_steps,\n",
        "                                          optimizer_type='adamw')\n",
        "\n",
        "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "metrics = tf.keras.metrics.CategoricalAccuracy()\n",
        "\n",
        "# compiling the model\n",
        "bert_bug_assignee_classifier.compile(optimizer=optimizer,\n",
        "                         loss=loss,\n",
        "                         metrics=metrics)"
      ],
      "metadata": {
        "id": "IfxUc_fP_uCD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2ae322e-7c30-4ad9-c98d-7d5f60d3adad"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "steps per epoch 138\n",
            "num train 2070\n",
            "num warmup 207\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizing our learning rate schedule"
      ],
      "metadata": {
        "id": "99q2dJQI83QE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "x = np.array([0,warmup_ratio,1])\n",
        "y = np.array([0, init_lr,0])\n",
        "plt.plot(x,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "NXhPPofV_6fl",
        "outputId": "f20e2193-ad33-4033-a89a-75a7f37ebf82"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fbf451b4f50>]"
            ]
          },
          "metadata": {},
          "execution_count": 82
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training BERT classifier"
      ],
      "metadata": {
        "id": "sddT1gRd85EA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Training BERT model with {tfhub_handle_encoder}')\n",
        "history = bert_bug_assignee_classifier.fit(x=train_dataset,\n",
        "                               validation_data=val_dataset,\n",
        "                               epochs=epochs,\n",
        "                               callbacks = [callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcZv5VoD5dGK",
        "outputId": "08bb19df-fb8c-4422-f508-11004d3a7742"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training BERT model with https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/2\n",
            "Epoch 1/15\n",
            "138/138 [==============================] - 36s 169ms/step - loss: 3.7539 - categorical_accuracy: 0.0609 - val_loss: 3.3524 - val_categorical_accuracy: 0.1293\n",
            "Epoch 2/15\n",
            "138/138 [==============================] - 22s 161ms/step - loss: 3.2892 - categorical_accuracy: 0.1402 - val_loss: 2.9085 - val_categorical_accuracy: 0.1929\n",
            "Epoch 3/15\n",
            "138/138 [==============================] - 22s 159ms/step - loss: 2.6979 - categorical_accuracy: 0.2600 - val_loss: 2.5809 - val_categorical_accuracy: 0.2866\n",
            "Epoch 4/15\n",
            "138/138 [==============================] - 22s 158ms/step - loss: 1.9967 - categorical_accuracy: 0.4454 - val_loss: 2.2533 - val_categorical_accuracy: 0.4095\n",
            "Epoch 5/15\n",
            "138/138 [==============================] - 22s 159ms/step - loss: 1.3819 - categorical_accuracy: 0.6221 - val_loss: 2.1695 - val_categorical_accuracy: 0.4612\n",
            "Epoch 6/15\n",
            "138/138 [==============================] - 22s 160ms/step - loss: 0.9031 - categorical_accuracy: 0.7647 - val_loss: 2.1428 - val_categorical_accuracy: 0.5183\n",
            "Epoch 7/15\n",
            "138/138 [==============================] - 22s 161ms/step - loss: 0.5550 - categorical_accuracy: 0.8616 - val_loss: 2.1488 - val_categorical_accuracy: 0.5388\n",
            "Epoch 8/15\n",
            "138/138 [==============================] - 22s 160ms/step - loss: 0.3276 - categorical_accuracy: 0.9216 - val_loss: 2.1589 - val_categorical_accuracy: 0.5550\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing the model on test dataset"
      ],
      "metadata": {
        "id": "pzAg334-89so"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = bert_bug_assignee_classifier.evaluate(test_dataset)\n",
        "\n",
        "print(f'Loss: {loss}')\n",
        "print(f'Accuracy: {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Tw3z1PYDajd",
        "outputId": "db8626c9-7166-4157-9d5d-578f46c69978"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29/29 [==============================] - 3s 105ms/step - loss: 2.2282 - categorical_accuracy: 0.5560\n",
            "Loss: 2.228231191635132\n",
            "Accuracy: 0.556034505367279\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving the model"
      ],
      "metadata": {
        "id": "8gE3Uu0Y_ezB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "saved_model_path = model_save_path + '/bert_model_4'"
      ],
      "metadata": {
        "id": "WKMPEIUFGf0x"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_bug_assignee_classifier.save(saved_model_path,include_optimizer=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d9788f2-e3d9-4bd3-8e2a-ed698623e6a2",
        "id": "nHhe-t9_Gf0y"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 66). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks//bert_model_4/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks//bert_model_4/assets\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    },
    "kernelspec": {
      "display_name": "Python 3.9.9 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.9"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "BAR.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}